{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gotta change the path and roi_list here to include the new ROIs I've made.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define path to input datasets (tidy format)\n",
    "path_to_recog = '/home/jefan/neurosketch_compmem/neurosketch_voxelmat_freesurfer_recog'#'/home/jgunn/neurosketch/recmatrices' #\n",
    "path_to_draw = '/home/jefan/neurosketch_compmem/neurosketch_voxelmat_freesurfer_drawing' #'/home/jgunn/neurosketch/drawmatrices' #\n",
    "roi_list = np.array(['V1','V2','LOC','IT','fusiform','parahippo', 'PRC', 'ento','hipp','mOFC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get raw file list for recognition runs\n",
    "RECOG_METAS = sorted([i for i in os.listdir(path_to_recog) if i.split('.')[-1]=='csv'])\n",
    "RECOG_FEATS = sorted([i for i in os.listdir(path_to_recog) if i.split('.')[-1]=='npy'])\n",
    "RECOG_SUBS = np.array([i.split('_')[0] for i in RECOG_FEATS])\n",
    "\n",
    "recog_sub_list = np.unique(RECOG_SUBS)\n",
    "\n",
    "def preprocess_recog(RECOG_METAS, RECOG_FEATS):\n",
    "    M = [i for i in RECOG_METAS if len(i.split('.')[0].split('_'))==4]\n",
    "    F = [i for i in RECOG_FEATS if len(i.split('.')[0].split('_'))==4]\n",
    "    return M,F\n",
    "\n",
    "RECOG_METAS, RECOG_FEATS = preprocess_recog(RECOG_METAS, RECOG_FEATS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get raw file list for drawing runs\n",
    "DRAW_METAS = sorted([i for i in os.listdir(path_to_draw) if i.split('.')[-1]=='csv'])\n",
    "DRAW_FEATS = sorted([i for i in os.listdir(path_to_draw) if i.split('.')[-1]=='npy'])\n",
    "DRAW_SUBS = np.array([i.split('_')[0] for i in DRAW_FEATS])\n",
    "draw_sub_list = np.unique(DRAW_SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subs: 31\n"
     ]
    }
   ],
   "source": [
    "## get subject ID's that have complete datasets from all phases of experiment\n",
    "sub_list = np.intersect1d(recog_sub_list,draw_sub_list)\n",
    "print('Number of subs: {}'.format(len(sub_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter file list so only contains the sessions that have full datasets\n",
    "def extract_good_sessions(DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS):\n",
    "    _DRAW_METAS = [i for i in DRAW_METAS if i.split('_')[1] in sub_list]\n",
    "    _DRAW_FEATS = [i for i in DRAW_FEATS if i.split('_')[0] in sub_list]\n",
    "    _RECOG_METAS = [i for i in RECOG_METAS if i.split('_')[1] in sub_list]\n",
    "    _RECOG_FEATS = [i for i in RECOG_FEATS if i.split('_')[0] in sub_list]\n",
    "    return _DRAW_METAS, _DRAW_FEATS, _RECOG_METAS, _RECOG_FEATS\n",
    "\n",
    "DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS =  \\\n",
    "extract_good_sessions(DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS)\n",
    "\n",
    "RECOG_SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in RECOG_FEATS])\n",
    "RECOG_ROIS = np.array([i.split('_')[1] for i in RECOG_FEATS])\n",
    "\n",
    "DRAW_SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in DRAW_FEATS])\n",
    "DRAW_ROIS = np.array([i.split('_')[1] for i in DRAW_FEATS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well do we do at classifying the target when we train on recognition patterns only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Helper data loader functions\n",
    "def load_draw_meta(this_sub):\n",
    "    this_file = 'metadata_{}_drawing.csv'.format(this_sub)\n",
    "    x = pd.read_csv(os.path.join(path_to_draw,this_file))\n",
    "    x = x.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "    x['trial_num'] = np.repeat(np.arange(40),23)        \n",
    "    return x\n",
    "    \n",
    "def load_draw_feats(this_sub,this_roi):\n",
    "    this_file = '{}_{}_featurematrix.npy'.format(this_sub,this_roi)\n",
    "    y = np.load(os.path.join(path_to_draw,this_file))\n",
    "    y = y.transpose()\n",
    "    return y\n",
    "\n",
    "def load_draw_data(this_sub,this_roi):\n",
    "    x = load_draw_meta(this_sub)\n",
    "    y = load_draw_feats(this_sub,this_roi)\n",
    "    assert y.shape[0] == x.shape[0]    \n",
    "    return x,y\n",
    "\n",
    "def load_recog_meta(this_sub,this_roi,this_phase):\n",
    "    this_file = 'metadata_{}_{}_{}.csv'.format(this_sub,this_roi,this_phase)\n",
    "    x = pd.read_csv(os.path.join(path_to_recog,this_file))\n",
    "    x = x.drop(['Unnamed: 0'], axis=1)\n",
    "    return x\n",
    "    \n",
    "def load_recog_feats(this_sub,this_roi,this_phase):\n",
    "    this_file = '{}_{}_{}_featurematrix.npy'.format(this_sub,this_roi,this_phase)\n",
    "    y = np.load(os.path.join(path_to_recog,this_file))\n",
    "    y = y.transpose()\n",
    "    return y    \n",
    "\n",
    "def load_recog_data(this_sub,this_roi,this_phase):\n",
    "    x = load_recog_meta(this_sub,this_roi,this_phase)\n",
    "    y = load_recog_feats(this_sub,this_roi,this_phase)\n",
    "    assert y.shape[0] == x.shape[0]    \n",
    "    return x,y\n",
    "\n",
    "# z-score normalization to de-mean & standardize variances within-voxel \n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "## plotting helper\n",
    "def get_prob_timecourse(iv,DM):\n",
    "    trained_objs = np.unique(DM.label.values)\n",
    "    control_objs = [i for i in ['bed','bench','chair','table'] if i not in trained_objs]\n",
    "    t1 = trained_objs[0]\n",
    "    t2 = trained_objs[1]\n",
    "    c1 = control_objs[0]\n",
    "    c2 = control_objs[1]\n",
    "    target = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(t1)].mean().values,\n",
    "                   DM[DM.label==t2].groupby(iv)['{}_prob'.format(t2)].mean().values)).mean(0) ## target timecourse\n",
    "    foil = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(t2)].mean().values,\n",
    "                   DM[DM.label==t2].groupby(iv)['{}_prob'.format(t1)].mean().values)).mean(0) ## foil timecourse\n",
    "    control = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(c1)].mean().values,\n",
    "                        DM[DM.label==t1].groupby(iv)['{}_prob'.format(c2)].mean().values,\n",
    "                        DM[DM.label==t2].groupby(iv)['{}_prob'.format(c1)].mean().values,\n",
    "                        DM[DM.label==t2].groupby(iv)['{}_prob'.format(c2)].mean().values)).mean(0) ## control timecourse\n",
    "    \n",
    "    return target, foil, control\n",
    "     \n",
    "def flatten(x):\n",
    "    return [item for sublist in x for item in sublist]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## general plotting params\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## example subject, roi, and phase (localizer is default)\n",
    "this_sub = sub_list[0]\n",
    "this_roi = roi_list[2] ## order is: ['V1','V2','LOC','IT','fusiform','parahippo', 'PRC', 'ento','hipp','mOFC']\n",
    "this_phase = '12' ## options are '12', '34', '56'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so to do my thing, I need to change the code so that it 1) subsets based on label instead of timepoint (one control label, and then another) 2) trains two classifiers, one for each subset, 3) take the mean of prediction probabilities, finally storing these in each <obj>_prob thing. Pretty straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "V2\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "LOC\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "IT\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "fusiform\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "parahippo\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "PRC\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "ento\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "hipp\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n",
      "mOFC\n",
      "0110171\n",
      "0110172\n",
      "0111171\n",
      "0112171\n",
      "0112172\n",
      "0112173\n",
      "0113171\n",
      "0115174\n",
      "0117171\n",
      "0118171\n",
      "0118172\n",
      "0119171\n",
      "0119172\n",
      "0119173\n",
      "0119174\n",
      "0120171\n",
      "0120172\n",
      "0120173\n",
      "0123171\n",
      "0123173\n",
      "0124171\n",
      "0125171\n",
      "0125172\n",
      "1121161\n",
      "1130161\n",
      "1202161\n",
      "1203161\n",
      "1206161\n",
      "1206162\n",
      "1206163\n",
      "1207162\n"
     ]
    }
   ],
   "source": [
    "ALLDM = []\n",
    "\n",
    "## loop through all subjects and rois\n",
    "Acc = []\n",
    "for this_roi in roi_list:\n",
    "    print (this_roi)\n",
    "    acc = []\n",
    "    for this_sub in sub_list:\n",
    "        print(this_sub)\n",
    "        ## load subject data in\n",
    "        RM12, RF12 = load_recog_data(this_sub,this_roi,'12')\n",
    "        RM34, RF34 = load_recog_data(this_sub,this_roi,'34')        \n",
    "        RM = pd.concat([RM12,RM34])\n",
    "        RF = np.vstack((RF12,RF34))        \n",
    "        DM, DF = load_draw_data(this_sub,this_roi)\n",
    "        assert RF.shape[1]==DF.shape[1] ## that number of voxels is identical\n",
    "\n",
    "        ## normalize voxels within task\n",
    "        normalize_on = 1\n",
    "        if normalize_on:\n",
    "            _RF = normalize(RF)\n",
    "            _DF = normalize(DF)\n",
    "        else:\n",
    "            _RF = RF\n",
    "            _DF = DF\n",
    "\n",
    "        # single train/test split\n",
    "        X_train = _RF # recognition run feature set\n",
    "        y_train = RM.label.values # list of labels for the training set\n",
    "\n",
    "        ## subset timepoints?\n",
    "        inds = DM.time_point>0 # all timepoints are > 0, so no subsetting happens\n",
    "        _DF = _DF[inds,:]\n",
    "        DM = DM[inds]\n",
    "\n",
    "        X_test = _DF\n",
    "        y_test = DM.label.values\n",
    "        # clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "        clf = linear_model.LogisticRegression(penalty='l2',C=1).fit(X_train, y_train)    \n",
    "\n",
    "        ## add prediction probabilities to metadata matrix\n",
    "        cats = clf.classes_\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        DM['bed_prob'] = probs[:,0]\n",
    "        DM['bench_prob'] = probs[:,1]\n",
    "        DM['chair_prob'] = probs[:,2]\n",
    "        DM['table_prob'] = probs[:,3]\n",
    "        \n",
    "        DM['subj'] = np.repeat(this_sub,DM.shape[0])\n",
    "        DM['roi'] = np.repeat(this_roi,DM.shape[0])\n",
    "        \n",
    "        if len(ALLDM)==0:\n",
    "            ALLDM = DM\n",
    "        else:\n",
    "            ALLDM = pd.concat([ALLDM,DM],ignore_index=True)\n",
    "\n",
    "        ## plot probability timecourse\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        iv = 'run_num'\n",
    "        t,f,c = get_prob_timecourse(iv,DM)\n",
    "        plt.plot(t,color=colors[0],label='target')\n",
    "        plt.plot(f,color=colors[1],label='foil')\n",
    "        plt.plot(c,color=colors[2],label='control')\n",
    "        plt.legend(bbox_to_anchor=(1.45, 1.01))\n",
    "        plt.ylim(0,1)\n",
    "        plt.xlabel(iv)\n",
    "        plt.ylabel('probability')\n",
    "        if not os.path.exists('./plots/subj'):\n",
    "            os.makedirs('./plots/subj')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('./plots/subj/{}_{}_prob_{}.pdf'.format(iv.split('_')[0],this_roi,this_sub))\n",
    "        plt.close(fig)\n",
    "        acc.append(clf.score(X_test, y_test))\n",
    "        \n",
    "    Acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #trained_objs = np.unique(DM.label.values)\n",
    "        #control_objs = [i for i in ['bed','bench','chair','table'] if i not in trained_objs]\n",
    "        #inds = DM.label != 'chair' # all timepoints are > 0, so no subsetting happens\n",
    "        \n",
    "#np.shape(probs)\n",
    "#(probs[0][:,0] + probs[1][:,0])/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALLDM = ALLDM.drop(['Unnamed: 0.1.1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>LOC</th>\n",
       "      <th>IT</th>\n",
       "      <th>fusiform</th>\n",
       "      <th>parahippo</th>\n",
       "      <th>PRC</th>\n",
       "      <th>ento</th>\n",
       "      <th>hipp</th>\n",
       "      <th>mOFC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.259783</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>0.263043</td>\n",
       "      <td>0.259783</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.248913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235870</td>\n",
       "      <td>0.202174</td>\n",
       "      <td>0.283696</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.266304</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.264130</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.266304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.234783</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.235870</td>\n",
       "      <td>0.264130</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.261957</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.245652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.314130</td>\n",
       "      <td>0.298913</td>\n",
       "      <td>0.202174</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.294565</td>\n",
       "      <td>0.280435</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.255435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.209783</td>\n",
       "      <td>0.298913</td>\n",
       "      <td>0.294565</td>\n",
       "      <td>0.251087</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.245652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.367391</td>\n",
       "      <td>0.377174</td>\n",
       "      <td>0.305435</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.283696</td>\n",
       "      <td>0.280435</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.255435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.305435</td>\n",
       "      <td>0.333696</td>\n",
       "      <td>0.308696</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.251087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.409783</td>\n",
       "      <td>0.401087</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.253261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.292391</td>\n",
       "      <td>0.307609</td>\n",
       "      <td>0.288043</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.233696</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.236957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.314130</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.259783</td>\n",
       "      <td>0.263043</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.255435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.377174</td>\n",
       "      <td>0.322826</td>\n",
       "      <td>0.279348</td>\n",
       "      <td>0.305435</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.284783</td>\n",
       "      <td>0.268478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.290217</td>\n",
       "      <td>0.297826</td>\n",
       "      <td>0.290217</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.238043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.317391</td>\n",
       "      <td>0.358696</td>\n",
       "      <td>0.278261</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.261957</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.255435</td>\n",
       "      <td>0.185870</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.261957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.283696</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.235870</td>\n",
       "      <td>0.201087</td>\n",
       "      <td>0.277174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.281522</td>\n",
       "      <td>0.283696</td>\n",
       "      <td>0.257609</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.229348</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.255435</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.223913</td>\n",
       "      <td>0.264130</td>\n",
       "      <td>0.267391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.320652</td>\n",
       "      <td>0.392391</td>\n",
       "      <td>0.286957</td>\n",
       "      <td>0.146739</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.238043</td>\n",
       "      <td>0.210870</td>\n",
       "      <td>0.265217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.261957</td>\n",
       "      <td>0.263043</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>0.205435</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.221739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.267391</td>\n",
       "      <td>0.297826</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.220652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.352174</td>\n",
       "      <td>0.419565</td>\n",
       "      <td>0.302174</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.194565</td>\n",
       "      <td>0.246739</td>\n",
       "      <td>0.251087</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.226087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.319565</td>\n",
       "      <td>0.335870</td>\n",
       "      <td>0.279348</td>\n",
       "      <td>0.292391</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.291304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.368478</td>\n",
       "      <td>0.377174</td>\n",
       "      <td>0.229348</td>\n",
       "      <td>0.207609</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.246739</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.218478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.330435</td>\n",
       "      <td>0.258696</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.196739</td>\n",
       "      <td>0.243478</td>\n",
       "      <td>0.228261</td>\n",
       "      <td>0.223913</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.253261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.222826</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.244565</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.269565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.284783</td>\n",
       "      <td>0.290217</td>\n",
       "      <td>0.256522</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.238043</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.278261</td>\n",
       "      <td>0.270652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.290217</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>0.264130</td>\n",
       "      <td>0.266304</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.251087</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.241304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.314130</td>\n",
       "      <td>0.395652</td>\n",
       "      <td>0.339130</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.254348</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.231522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.236957</td>\n",
       "      <td>0.246739</td>\n",
       "      <td>0.291304</td>\n",
       "      <td>0.203261</td>\n",
       "      <td>0.272826</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.221739</td>\n",
       "      <td>0.316304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.289130</td>\n",
       "      <td>0.253261</td>\n",
       "      <td>0.264130</td>\n",
       "      <td>0.241304</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.238043</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.247826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.242391</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.291304</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.278261</td>\n",
       "      <td>0.248913</td>\n",
       "      <td>0.269565</td>\n",
       "      <td>0.232609</td>\n",
       "      <td>0.243478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.279348</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.252174</td>\n",
       "      <td>0.285870</td>\n",
       "      <td>0.230435</td>\n",
       "      <td>0.266304</td>\n",
       "      <td>0.273913</td>\n",
       "      <td>0.247826</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>0.236957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1        V2       LOC        IT  fusiform  parahippo       PRC  \\\n",
       "0   0.267391  0.259783  0.282609  0.244565  0.231522   0.263043  0.259783   \n",
       "1   0.235870  0.202174  0.283696  0.241304  0.266304   0.241304  0.232609   \n",
       "2   0.226087  0.234783  0.232609  0.293478  0.235870   0.264130  0.254348   \n",
       "3   0.314130  0.298913  0.202174  0.236957  0.294565   0.280435  0.258696   \n",
       "4   0.209783  0.298913  0.294565  0.251087  0.254348   0.268478  0.272826   \n",
       "5   0.367391  0.377174  0.305435  0.256522  0.283696   0.280435  0.222826   \n",
       "6   0.305435  0.333696  0.308696  0.275000  0.225000   0.217391  0.230435   \n",
       "7   0.409783  0.401087  0.313043  0.254348  0.217391   0.236957  0.222826   \n",
       "8   0.303261  0.292391  0.307609  0.288043  0.239130   0.257609  0.267391   \n",
       "9   0.329348  0.314130  0.204348  0.230435  0.239130   0.248913  0.259783   \n",
       "10  0.289130  0.377174  0.322826  0.279348  0.305435   0.258696  0.275000   \n",
       "11  0.290217  0.297826  0.290217  0.248913  0.269565   0.221739  0.239130   \n",
       "12  0.317391  0.358696  0.278261  0.240217  0.261957   0.260870  0.255435   \n",
       "13  0.230435  0.208696  0.239130  0.282609  0.252174   0.283696  0.248913   \n",
       "14  0.281522  0.283696  0.257609  0.253261  0.221739   0.247826  0.229348   \n",
       "15  0.250000  0.321739  0.255435  0.256522  0.265217   0.230435  0.241304   \n",
       "16  0.320652  0.392391  0.286957  0.146739  0.300000   0.236957  0.217391   \n",
       "17  0.261957  0.263043  0.245652  0.205435  0.232609   0.232609  0.258696   \n",
       "18  0.267391  0.267391  0.267391  0.297826  0.325000   0.272826  0.231522   \n",
       "19  0.352174  0.419565  0.302174  0.241304  0.253261   0.194565  0.246739   \n",
       "20  0.319565  0.335870  0.279348  0.292391  0.258696   0.252174  0.273913   \n",
       "21  0.368478  0.377174  0.229348  0.207609  0.256522   0.246739  0.256522   \n",
       "22  0.330435  0.258696  0.268478  0.248913  0.196739   0.243478  0.228261   \n",
       "23  0.222826  0.239130  0.232609  0.248913  0.208696   0.244565  0.230435   \n",
       "24  0.284783  0.290217  0.256522  0.191304  0.225000   0.238043  0.240217   \n",
       "25  0.290217  0.289130  0.303261  0.226087  0.264130   0.266304  0.247826   \n",
       "26  0.314130  0.395652  0.339130  0.230435  0.254348   0.245652  0.204348   \n",
       "27  0.236957  0.246739  0.291304  0.203261  0.272826   0.245652  0.230435   \n",
       "28  0.329348  0.329348  0.289130  0.253261  0.264130   0.241304  0.239130   \n",
       "29  0.242391  0.271739  0.260870  0.291304  0.275000   0.278261  0.248913   \n",
       "30  0.279348  0.329348  0.252174  0.285870  0.230435   0.266304  0.273913   \n",
       "\n",
       "        ento      hipp      mOFC  \n",
       "0   0.257609  0.247826  0.248913  \n",
       "1   0.264130  0.258696  0.266304  \n",
       "2   0.261957  0.252174  0.245652  \n",
       "3   0.221739  0.240217  0.255435  \n",
       "4   0.271739  0.257609  0.245652  \n",
       "5   0.225000  0.252174  0.255435  \n",
       "6   0.247826  0.253261  0.251087  \n",
       "7   0.257609  0.260870  0.253261  \n",
       "8   0.233696  0.257609  0.236957  \n",
       "9   0.263043  0.241304  0.255435  \n",
       "10  0.253261  0.284783  0.268478  \n",
       "11  0.240217  0.252174  0.238043  \n",
       "12  0.185870  0.244565  0.261957  \n",
       "13  0.235870  0.201087  0.277174  \n",
       "14  0.250000  0.269565  0.164130  \n",
       "15  0.223913  0.264130  0.267391  \n",
       "16  0.238043  0.210870  0.265217  \n",
       "17  0.243478  0.232609  0.221739  \n",
       "18  0.242391  0.240217  0.220652  \n",
       "19  0.251087  0.232609  0.226087  \n",
       "20  0.252174  0.230435  0.291304  \n",
       "21  0.242391  0.248913  0.218478  \n",
       "22  0.223913  0.260870  0.253261  \n",
       "23  0.273913  0.191304  0.269565  \n",
       "24  0.232609  0.278261  0.270652  \n",
       "25  0.251087  0.206522  0.241304  \n",
       "26  0.245652  0.250000  0.231522  \n",
       "27  0.241304  0.221739  0.316304  \n",
       "28  0.238043  0.268478  0.247826  \n",
       "29  0.269565  0.232609  0.243478  \n",
       "30  0.247826  0.245652  0.236957  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc = np.array(Acc) # 10 ROIs, 31 subjects. A score representing classification performance for that subject/roi pair\n",
    "x = pd.DataFrame(Acc.transpose())\n",
    "x.columns = roi_list\n",
    "\n",
    "x # x is acc formatted into a ROI x subject dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.35)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAEOCAYAAABFFeUyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhzUIAiCIAiCIFeEgxoEQRAEQRDkiv8ACWTLrzXLLaEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9821114e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(11,4))\n",
    "sns.barplot(data=x,palette='husl',ci=95) # very amazing thing sns must be!\n",
    "plt.axhline(.25,linestyle=':',color='k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('test on drawing runs; train on recognition runs')\n",
    "plt.ylim(0,0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALLDM.to_csv('./logistic_timeseries_neural_vgg.csv') ## train recog, test drawing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TR_num</th>\n",
       "      <th>bed_prob</th>\n",
       "      <th>bench_prob</th>\n",
       "      <th>chair_prob</th>\n",
       "      <th>label</th>\n",
       "      <th>roi</th>\n",
       "      <th>run_num</th>\n",
       "      <th>subj</th>\n",
       "      <th>table_prob</th>\n",
       "      <th>time_point</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.785917</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.010464</td>\n",
       "      <td>bed</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>0110171</td>\n",
       "      <td>0.189855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.943448</td>\n",
       "      <td>0.012615</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>bed</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>0110171</td>\n",
       "      <td>0.031231</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.223766</td>\n",
       "      <td>0.118172</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>bed</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>0110171</td>\n",
       "      <td>0.637351</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.429318</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>bed</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>0110171</td>\n",
       "      <td>0.552225</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.399308</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.054215</td>\n",
       "      <td>bed</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>0110171</td>\n",
       "      <td>0.545701</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TR_num  bed_prob  bench_prob  chair_prob label roi  run_num     subj  \\\n",
       "0      10  0.785917    0.013764    0.010464   bed  V1        1  0110171   \n",
       "1      11  0.943448    0.012615    0.012706   bed  V1        1  0110171   \n",
       "2      12  0.223766    0.118172    0.020711   bed  V1        1  0110171   \n",
       "3      13  0.018425    0.429318    0.000032   bed  V1        1  0110171   \n",
       "4      14  0.399308    0.000777    0.054215   bed  V1        1  0110171   \n",
       "\n",
       "   table_prob  time_point  trial_num  \n",
       "0    0.189855           1          0  \n",
       "1    0.031231           2          0  \n",
       "2    0.637351           3          0  \n",
       "3    0.552225           4          0  \n",
       "4    0.545701           5          0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALLDM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how does this code work?\n",
    "\n",
    "`lookup` is weird.\n",
    "\n",
    "Scans through `['run_num','trial_num','time_point']`, then ROIs, then subjects too.\n",
    "\n",
    "Now what is T F C? Trained, Foil Control. uses the helper function on a subset of ALLDMS that focuses on this roi and this subject. How does that function work?\n",
    "seems to first take the unique set of labels..? How is he telling between trained and untrained objs? Seems there's an ordering, and unique preserves it? Drawing trials will always only be the trained ones. Duh. Control is never the accurate thing, but it always gets assigned a score. This'll make the other coding problem easier.\n",
    "\n",
    "So it isolates by roi, subject and object, groups iteratively by ['run_num','trial_num','time_point'] and takes the mean across those groupings for each object category. So I get 4 means for 4 runs, and 3 sets of means, one for each condition. Need more focus on how foil is calculated, though. It's just t2, that's all.\n",
    "\n",
    "So let's start over knowing what I know. Scanning through the units I want my timecourse taken over (runs, trials, timepoints), then over ROIs, then over subjects. On the subject level, I'm getting the probability time course over the current iv for trained, foil, and control. For each sub, store said timecourse in T, F, or C. DTF DTC and DFC are the differences from D to F, etc. If render cond is positive, the plot will be trained, foil, control. Otherwise, it's DTF and so forth. \n",
    "\n",
    "Then generate graph for this. DOn't know if I need to know the details. I'm looking to set up the final graphs. Instead of drawing from mean over this probability time course, draw the max or the max difference. \n",
    "\n",
    "Seems I also need to do this for DTF over repetitions. Take correlations of these for each subject (rather than max or mean). ANd then plot those correlations. Where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "this_roi = 'V1'\n",
    "subs = np.unique(ALLDM.subj.values) # list of subjects pulled from ALLDM.\n",
    "lookup = dict(zip(['trial_num','run_num','time_point'],['repetition','run','TR']))\n",
    "ivs = ['run_num','trial_num','time_point']\n",
    "this_iv = 'time_point'\n",
    "\n",
    "## do you want to render the CONDITION-wise plots -- trained vs. foil vs control\n",
    "## or the DIFFERENCE plots -- trained - foil vs foil - control?\n",
    "render_cond = 0\n",
    "\n",
    "for this_iv in ivs:\n",
    "    for this_roi in roi_list:\n",
    "\n",
    "        T = []\n",
    "        F = []\n",
    "        C = []\n",
    "        Sub = []\n",
    "        for sub in subs:\n",
    "            inds =(ALLDM['roi']==this_roi) & (ALLDM['subj']==sub) \n",
    "            t,f,c = get_prob_timecourse(this_iv,ALLDM[inds])\n",
    "            if len(T)==0:\n",
    "                T = t\n",
    "                F = f\n",
    "                C = c\n",
    "                DTF = t-f                \n",
    "                DTC = t-c\n",
    "                DFC = f-c\n",
    "            else:\n",
    "                T = np.hstack((T,t))\n",
    "                F = np.hstack((F,f))        \n",
    "                C = np.hstack((C,c)) \n",
    "                DTF = np.hstack((DTF,t-f))                \n",
    "                DTC = np.hstack((DTC,t-c))\n",
    "                DFC = np.hstack((DFC,f-c))\n",
    "            Sub.append([sub]*len(t))   \n",
    "        \n",
    "        if render_cond==1:\n",
    "            ## make longform version of dataframe to use in tsplot (by condition)            \n",
    "            Trial = np.tile(np.arange(len(t)),len(subs)*3)\n",
    "            Condition = np.repeat(['trained','foil','control'],len(T))\n",
    "            Sub = np.tile(np.array(flatten(Sub)),3)\n",
    "            Prob = np.hstack((T,F,C))\n",
    "            assert len(Trial)==len(Condition)\n",
    "            assert len(Sub)==len(Prob)\n",
    "            assert len(Condition)==len(Sub)\n",
    "            x = pd.DataFrame([Prob,Trial,Condition,Sub])\n",
    "            x = x.transpose()\n",
    "            x.columns = ['probability',lookup[this_iv],'condition','sub']\n",
    "            toop = 'condition'\n",
    "        else:\n",
    "            ## make longform version of dataframe to use in tsplot (difference btw conditions)                    \n",
    "            Trial = np.tile(np.arange(len(t)),len(subs)*3)\n",
    "            Condition = np.repeat(['trained-foil','trained-control','foil-control'],len(T))\n",
    "            Sub = np.tile(np.array(flatten(Sub)),3)\n",
    "            Prob = np.hstack((DTF,DTC,DFC))        \n",
    "            assert len(Trial)==len(Condition)\n",
    "            assert len(Sub)==len(Prob)\n",
    "            assert len(Condition)==len(Sub)\n",
    "            x = pd.DataFrame([Prob,Trial,Condition,Sub])\n",
    "            x = x.transpose()\n",
    "            x.columns = ['probability',lookup[this_iv],'condition','sub']        \n",
    "            toop = 'difference'\n",
    "        \n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        ## plot it\n",
    "        sns.tsplot(data=x,\n",
    "                  time=lookup[this_iv],\n",
    "                  unit='sub',\n",
    "                  condition='condition',\n",
    "                  value='probability',\n",
    "                  ci=95)\n",
    "        if render_cond==1:\n",
    "            plt.ylim(0,2/3)\n",
    "            plt.axhline(1/3,linestyle=':',color='k')  \n",
    "            plt.legend(bbox_to_anchor=(0.8, 1.01))  \n",
    "            plt.title('Classifier evidence by condition in {}'.format(this_roi))\n",
    "            \n",
    "        else:\n",
    "            plt.ylim(-0.3,0.3)\n",
    "            plt.axhline(0,linestyle=':',color='k')  \n",
    "            plt.legend(bbox_to_anchor=(0.7, 1.01))                        \n",
    "            plt.title('Difference in classifier evidence by condition in {}'.format(this_roi))        \n",
    "        plt.xticks(np.arange(np.max(x[lookup[this_iv]].values)+1))\n",
    "        if not os.path.exists('./plots/roi/{}/{}'.format(lookup[this_iv],toop)):\n",
    "            os.makedirs('./plots/roi/{}/{}'.format(lookup[this_iv],toop))\n",
    "        plt.tight_layout()        \n",
    "        plt.savefig('./plots/roi/{}/{}/prob_timecourse_{}_by_{}.pdf'.\\\n",
    "                    format(lookup[this_iv],toop,this_roi,lookup[this_iv]))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>run</th>\n",
       "      <th>condition</th>\n",
       "      <th>sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0404719</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0737506</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0494378</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0615078</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00639958</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0193228</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.0654076</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.0331246</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0110172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0141114</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0111171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00427826</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0111171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0570437</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0111171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0179295</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0111171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.000429751</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00123387</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.113223</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0270371</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00349888</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0266975</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0295628</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0622316</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.169847</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.131437</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.15423</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.104267</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0112173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.129194</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0867317</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0255317</td>\n",
       "      <td>2</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.104384</td>\n",
       "      <td>3</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.159812</td>\n",
       "      <td>0</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0115174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.345147</td>\n",
       "      <td>1</td>\n",
       "      <td>trained-foil</td>\n",
       "      <td>0115174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.0585994</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1121161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.0506289</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1121161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.202001</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1130161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.0124933</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1130161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.0793226</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1130161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.168675</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1130161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.362513</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1202161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.0933041</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1202161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>-0.112705</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1202161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.203673</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1202161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.273435</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>-0.195254</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.0141931</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.315756</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>-0.0396553</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.0576922</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0897579</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>-0.0806067</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-0.257225</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>-0.0347464</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.221568</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.0149702</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>-0.047807</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.0223511</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>-0.0764515</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>-0.0500935</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1206163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.0209393</td>\n",
       "      <td>0</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1207162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>-0.144033</td>\n",
       "      <td>1</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1207162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>0.0695894</td>\n",
       "      <td>2</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1207162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.0141555</td>\n",
       "      <td>3</td>\n",
       "      <td>foil-control</td>\n",
       "      <td>1207162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability run     condition      sub\n",
       "0      0.0404719   0  trained-foil  0110171\n",
       "1      0.0737506   1  trained-foil  0110171\n",
       "2      0.0494378   2  trained-foil  0110171\n",
       "3      0.0615078   3  trained-foil  0110171\n",
       "4     0.00639958   0  trained-foil  0110172\n",
       "5      0.0193228   1  trained-foil  0110172\n",
       "6     -0.0654076   2  trained-foil  0110172\n",
       "7     -0.0331246   3  trained-foil  0110172\n",
       "8      0.0141114   0  trained-foil  0111171\n",
       "9     0.00427826   1  trained-foil  0111171\n",
       "10    -0.0570437   2  trained-foil  0111171\n",
       "11     0.0179295   3  trained-foil  0111171\n",
       "12  -0.000429751   0  trained-foil  0112171\n",
       "13    0.00123387   1  trained-foil  0112171\n",
       "14      0.113223   2  trained-foil  0112171\n",
       "15     0.0270371   3  trained-foil  0112171\n",
       "16    0.00349888   0  trained-foil  0112172\n",
       "17     0.0266975   1  trained-foil  0112172\n",
       "18     0.0295628   2  trained-foil  0112172\n",
       "19     0.0622316   3  trained-foil  0112172\n",
       "20      0.169847   0  trained-foil  0112173\n",
       "21      0.131437   1  trained-foil  0112173\n",
       "22       0.15423   2  trained-foil  0112173\n",
       "23      0.104267   3  trained-foil  0112173\n",
       "24      0.129194   0  trained-foil  0113171\n",
       "25     0.0867317   1  trained-foil  0113171\n",
       "26     0.0255317   2  trained-foil  0113171\n",
       "27      0.104384   3  trained-foil  0113171\n",
       "28      0.159812   0  trained-foil  0115174\n",
       "29      0.345147   1  trained-foil  0115174\n",
       "..           ...  ..           ...      ...\n",
       "342   -0.0585994   2  foil-control  1121161\n",
       "343   -0.0506289   3  foil-control  1121161\n",
       "344     0.202001   0  foil-control  1130161\n",
       "345    0.0124933   1  foil-control  1130161\n",
       "346    0.0793226   2  foil-control  1130161\n",
       "347    -0.168675   3  foil-control  1130161\n",
       "348     0.362513   0  foil-control  1202161\n",
       "349   -0.0933041   1  foil-control  1202161\n",
       "350    -0.112705   2  foil-control  1202161\n",
       "351    -0.203673   3  foil-control  1202161\n",
       "352    -0.273435   0  foil-control  1203161\n",
       "353    -0.195254   1  foil-control  1203161\n",
       "354   -0.0141931   2  foil-control  1203161\n",
       "355     0.315756   3  foil-control  1203161\n",
       "356   -0.0396553   0  foil-control  1206161\n",
       "357    0.0576922   1  foil-control  1206161\n",
       "358    0.0897579   2  foil-control  1206161\n",
       "359   -0.0806067   3  foil-control  1206161\n",
       "360    -0.257225   0  foil-control  1206162\n",
       "361   -0.0347464   1  foil-control  1206162\n",
       "362     0.221568   2  foil-control  1206162\n",
       "363    0.0149702   3  foil-control  1206162\n",
       "364    -0.047807   0  foil-control  1206163\n",
       "365    0.0223511   1  foil-control  1206163\n",
       "366   -0.0764515   2  foil-control  1206163\n",
       "367   -0.0500935   3  foil-control  1206163\n",
       "368    0.0209393   0  foil-control  1207162\n",
       "369    -0.144033   1  foil-control  1207162\n",
       "370    0.0695894   2  foil-control  1207162\n",
       "371    0.0141555   3  foil-control  1207162\n",
       "\n",
       "[372 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean...Seems to be calculate of the bottom part of the graph. Look for the mean...There it is! Just swap that for max, and you have it. Though, that's the max difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get subject-level index of contrast between objects during drawing\n",
    "sub_tf = []\n",
    "sub_tc = []\n",
    "sub_fc = []\n",
    "roi = []\n",
    "\n",
    "subs = np.unique(ALLDM.subj.values)\n",
    "ivs = ['time_point'] ## other optoins 'run_num','trial_num',\n",
    "\n",
    "## do you want to render the CONDITION-wise plots -- trained vs. foil vs control\n",
    "## or the DIFFERENCE plots -- trained - foil vs foil - control?\n",
    "render_cond = 0\n",
    "\n",
    "for this_iv in ivs:\n",
    "    for this_roi in roi_list:\n",
    "\n",
    "        T = []\n",
    "        F = []\n",
    "        C = []\n",
    "        Sub = []\n",
    "        for sub in subs:\n",
    "            inds =(ALLDM['roi']==this_roi) & (ALLDM['subj']==sub) \n",
    "            t,f,c = get_prob_timecourse(this_iv,ALLDM[inds])\n",
    "            if len(T)==0:\n",
    "                T = t\n",
    "                F = f\n",
    "                C = c\n",
    "                DTF = t-f                \n",
    "                DTC = t-c\n",
    "                DFC = f-c\n",
    "            else:\n",
    "                T = np.hstack((T,t))\n",
    "                F = np.hstack((F,f))        \n",
    "                C = np.hstack((C,c)) \n",
    "                DTF = np.hstack((DTF,t-f))                \n",
    "                DTC = np.hstack((DTC,t-c))\n",
    "                DFC = np.hstack((DFC,f-c))\n",
    "            Sub.append([sub]*len(t))   \n",
    "          \n",
    "        ## make longform version of dataframe to use in tsplot (difference btw conditions)                    \n",
    "        Trial = np.tile(np.arange(len(t)),len(subs)*3)\n",
    "        Condition = np.repeat(['trained-foil','trained-control','foil-control'],len(T))\n",
    "        Sub = np.tile(np.array(flatten(Sub)),3)\n",
    "        Prob = np.hstack((DTF,DTC,DFC))        \n",
    "        assert len(Trial)==len(Condition)\n",
    "        assert len(Sub)==len(Prob)\n",
    "        assert len(Condition)==len(Sub)\n",
    "        x = pd.DataFrame([Prob,Trial,Condition,Sub])\n",
    "        x = x.transpose()\n",
    "        x.columns = ['probability',lookup[this_iv],'condition','sub']\n",
    "        \n",
    "        for this_sub in subs:\n",
    "            sub_tf.append(x[(x['condition']=='trained-foil') & (x['sub']==this_sub)]['probability'].max())\n",
    "            sub_tc.append(x[(x['condition']=='trained-control') & (x['sub']==this_sub)]['probability'].max())  \n",
    "            sub_fc.append(x[(x['condition']=='foil-control') & (x['sub']==this_sub)]['probability'].max()) \n",
    "            roi.append(this_roi)\n",
    "    \n",
    "## make dataframe with subject-level difference scores\n",
    "d = pd.DataFrame([sub_tf,sub_tc,sub_fc,roi])\n",
    "d = d.transpose()\n",
    "d.columns = ['trained-foil','trained-control','foil-control','roi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trained-foil</th>\n",
       "      <th>trained-control</th>\n",
       "      <th>foil-control</th>\n",
       "      <th>roi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185717</td>\n",
       "      <td>0.195641</td>\n",
       "      <td>0.125113</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0908479</td>\n",
       "      <td>0.0933743</td>\n",
       "      <td>0.13579</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0916103</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.173766</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175871</td>\n",
       "      <td>0.192133</td>\n",
       "      <td>0.168488</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127796</td>\n",
       "      <td>0.188012</td>\n",
       "      <td>0.100075</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.263166</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.0520965</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.280682</td>\n",
       "      <td>0.289652</td>\n",
       "      <td>0.126799</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.303142</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.0665906</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.196149</td>\n",
       "      <td>0.235601</td>\n",
       "      <td>0.170101</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.187201</td>\n",
       "      <td>0.227087</td>\n",
       "      <td>0.183426</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.307415</td>\n",
       "      <td>0.196326</td>\n",
       "      <td>-0.0346654</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.132527</td>\n",
       "      <td>0.194278</td>\n",
       "      <td>0.0991486</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.311228</td>\n",
       "      <td>0.276345</td>\n",
       "      <td>0.0591248</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.130229</td>\n",
       "      <td>0.136687</td>\n",
       "      <td>0.0907079</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.23704</td>\n",
       "      <td>0.21143</td>\n",
       "      <td>0.113997</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.156597</td>\n",
       "      <td>0.168381</td>\n",
       "      <td>0.0981232</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.219839</td>\n",
       "      <td>0.136468</td>\n",
       "      <td>0.0072043</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.142844</td>\n",
       "      <td>0.133341</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.173206</td>\n",
       "      <td>0.206493</td>\n",
       "      <td>0.125955</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.284922</td>\n",
       "      <td>0.223316</td>\n",
       "      <td>0.0655863</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.27025</td>\n",
       "      <td>0.195932</td>\n",
       "      <td>0.0708852</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.252321</td>\n",
       "      <td>0.255265</td>\n",
       "      <td>0.10517</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.245052</td>\n",
       "      <td>0.258392</td>\n",
       "      <td>0.0619909</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0208815</td>\n",
       "      <td>0.0514725</td>\n",
       "      <td>0.0938689</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.238624</td>\n",
       "      <td>0.153605</td>\n",
       "      <td>0.116075</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.17616</td>\n",
       "      <td>0.207396</td>\n",
       "      <td>0.0713558</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.278967</td>\n",
       "      <td>0.26183</td>\n",
       "      <td>0.0421058</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0538153</td>\n",
       "      <td>0.170537</td>\n",
       "      <td>0.223824</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.300274</td>\n",
       "      <td>0.286724</td>\n",
       "      <td>0.152199</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.125887</td>\n",
       "      <td>0.16548</td>\n",
       "      <td>0.0829023</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.149171</td>\n",
       "      <td>0.200969</td>\n",
       "      <td>0.0970085</td>\n",
       "      <td>V1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trained-foil trained-control foil-control roi\n",
       "0      0.185717        0.195641     0.125113  V1\n",
       "1     0.0908479       0.0933743      0.13579  V1\n",
       "2     0.0916103        0.227232     0.173766  V1\n",
       "3      0.175871        0.192133     0.168488  V1\n",
       "4      0.127796        0.188012     0.100075  V1\n",
       "5      0.263166        0.204339    0.0520965  V1\n",
       "6      0.280682        0.289652     0.126799  V1\n",
       "7      0.303142        0.241618    0.0665906  V1\n",
       "8      0.196149        0.235601     0.170101  V1\n",
       "9      0.187201        0.227087     0.183426  V1\n",
       "10     0.307415        0.196326   -0.0346654  V1\n",
       "11     0.132527        0.194278    0.0991486  V1\n",
       "12     0.311228        0.276345    0.0591248  V1\n",
       "13     0.130229        0.136687    0.0907079  V1\n",
       "14      0.23704         0.21143     0.113997  V1\n",
       "15     0.156597        0.168381    0.0981232  V1\n",
       "16     0.219839        0.136468    0.0072043  V1\n",
       "17     0.150206        0.142844     0.133341  V1\n",
       "18     0.173206        0.206493     0.125955  V1\n",
       "19     0.284922        0.223316    0.0655863  V1\n",
       "20      0.27025        0.195932    0.0708852  V1\n",
       "21     0.252321        0.255265      0.10517  V1\n",
       "22     0.245052        0.258392    0.0619909  V1\n",
       "23    0.0208815       0.0514725    0.0938689  V1\n",
       "24     0.238624        0.153605     0.116075  V1\n",
       "25      0.17616        0.207396    0.0713558  V1\n",
       "26     0.278967         0.26183    0.0421058  V1\n",
       "27    0.0538153        0.170537     0.223824  V1\n",
       "28     0.300274        0.286724     0.152199  V1\n",
       "29     0.125887         0.16548    0.0829023  V1\n",
       "30     0.149171        0.200969    0.0970085  V1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d['roi']=='V1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just tests if any of these differences are reliably different from zero. Some are, even taking into account multiple measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI = V1 | t = 13.88801051243706, p = 1.33324708172452e-14\n",
      "ROI = V2 | t = 15.115995027809639, p = 1.4284432938184873e-15\n",
      "ROI = LOC | t = 13.508714272646115, p = 2.7383564209820234e-14\n",
      "ROI = IT | t = 17.01498352853847, p = 5.879418459447529e-17\n",
      "ROI = fusiform | t = 21.184153339047743, p = 1.3422919432112026e-19\n",
      "ROI = parahippo | t = 19.87119131879196, p = 8.085423140713453e-19\n",
      "ROI = PRC | t = 18.64019456695917, p = 4.790587197038086e-18\n",
      "ROI = ento | t = 18.463747911425553, p = 6.2327475119528026e-18\n",
      "ROI = hipp | t = 16.947208082904886, p = 6.555222842689191e-17\n",
      "ROI = mOFC | t = 17.058544337807298, p = 5.4833378533369086e-17\n"
     ]
    }
   ],
   "source": [
    "for this_roi in roi_list:\n",
    "    data = d[d['roi']==this_roi]['trained-foil']\n",
    "    t,p = stats.ttest_1samp(data,0)\n",
    "    print ('ROI = {} | t = {}, p = {}'.format(this_roi,t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI = V1 | t = 20.63981032076996, p = 2.791955745656528e-19\n",
      "ROI = V2 | t = 17.7666100999761, p = 1.8006100078352804e-17\n",
      "ROI = LOC | t = 13.498578527748764, p = 2.7920970396339826e-14\n",
      "ROI = IT | t = 15.286794502223199, p = 1.058698841161701e-15\n",
      "ROI = fusiform | t = 15.347442677476682, p = 9.524712459871078e-16\n",
      "ROI = parahippo | t = 18.524932945818623, p = 5.6877918743730295e-18\n",
      "ROI = PRC | t = 18.419965634449504, p = 6.6555143638767934e-18\n",
      "ROI = ento | t = 20.6751793178671, p = 2.6608517433046425e-19\n",
      "ROI = hipp | t = 19.822402098241433, p = 8.660345808702501e-19\n",
      "ROI = mOFC | t = 14.057768346684334, p = 9.706234897426041e-15\n"
     ]
    }
   ],
   "source": [
    "for this_roi in roi_list:\n",
    "    data = d[d['roi']==this_roi]['trained-control']\n",
    "    t,p = stats.ttest_1samp(data,0)\n",
    "    print ('ROI = {} | t = {}, p = {}'.format(this_roi,t,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI = V1 | t = 10.744707790906867, p = 8.368124139191341e-12\n",
      "ROI = V2 | t = 9.70800971302406, p = 9.081508462514136e-11\n",
      "ROI = LOC | t = 11.394349300022554, p = 2.0123932258470115e-12\n",
      "ROI = IT | t = 20.54799587022388, p = 3.164298750620144e-19\n",
      "ROI = fusiform | t = 14.136301035270952, p = 8.38868270112384e-15\n",
      "ROI = parahippo | t = 23.670571363705637, p = 5.7694585608998255e-21\n",
      "ROI = PRC | t = 25.494477521033524, p = 6.8932323115770585e-22\n",
      "ROI = ento | t = 18.084750827891177, p = 1.1048789290635108e-17\n",
      "ROI = hipp | t = 21.233052565749126, p = 1.2578447794303106e-19\n",
      "ROI = mOFC | t = 16.928274467013587, p = 6.757959695000384e-17\n"
     ]
    }
   ],
   "source": [
    "for this_roi in roi_list:\n",
    "    data = d[d['roi']==this_roi]['foil-control']\n",
    "    t,p = stats.ttest_1samp(data,0)\n",
    "    print ('ROI = {} | t = {}, p = {}'.format(this_roi,t,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple graph. X is foil-control, y is prepostdiff scores. Plot points, correlation, etc. All I'm changing is x-axis, and I'm doing it above. Cool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepost = pd.read_csv('neural_changes_by_surfroi_and_subject.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "V2\n",
      "LOC\n",
      "IT\n",
      "fusiform\n",
      "parahippo\n",
      "PRC\n",
      "ento\n",
      "hipp\n",
      "mOFC\n"
     ]
    }
   ],
   "source": [
    "## make dataframe to relate drawing contrast to recognition differentiation\n",
    "roi_list = ['V1', 'V2', 'LOC', 'IT', 'fusiform', 'parahippo', 'PRC', 'ento','hipp', 'mOFC']\n",
    "this_roi = 'hipp'\n",
    "\n",
    "for this_roi in roi_list:\n",
    "    print(this_roi)\n",
    "    draw = d[d['roi']==this_roi]['trained-foil'].values #d[d['roi']==this_roi]['trained-control'].values - d[d['roi']==this_roi]['foil-control'].values\n",
    "    recog = prepost['tradiff_{}'.format(this_roi)].values-prepost['condiff_{}'.format(this_roi)].values\n",
    "\n",
    "    z = pd.DataFrame([draw,recog])\n",
    "    z = z.transpose()\n",
    "    z.columns=['draw','recog']\n",
    "\n",
    "    ## plot \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sns.set_context('poster')\n",
    "    sns.regplot(x=\"draw\",\n",
    "                y =\"recog\",\n",
    "                data=z)\n",
    "    r,p = stats.pearsonr(draw,recog)\n",
    "    plt.title('ROI: {}  r={}  p={}'.format(this_roi,np.round(r,3),np.round(p,3)))\n",
    "    if not os.path.exists('./plots/roi/drawrecog'):\n",
    "        os.makedirs('./plots/roi/drawrecog')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./plots/roi/drawrecog/draw_recog_scatter_{}.pdf'.format(this_roi))\n",
    "    plt.close(fig)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relate neural to vgg drawing time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./logistic_timeseries_drawing_vgg.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-171bafc1696e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logistic_timeseries_drawing_vgg.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mneural_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./logistic_timeseries_drawing_neural.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./logistic_timeseries_drawing_vgg.csv' does not exist"
     ]
    }
   ],
   "source": [
    "vgg_ts = pd.read_csv('./logistic_timeseries_drawing_vgg.csv')\n",
    "neural_ts = pd.read_csv('./logistic_timeseries_drawing_neural.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_ts = vgg_ts.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n",
    "vgg_ts.wID = [i.split('_')[0] for i in vgg_ts.wID.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>wID</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>trial</th>\n",
       "      <th>trialDuration</th>\n",
       "      <th>target</th>\n",
       "      <th>competitor</th>\n",
       "      <th>numSketch</th>\n",
       "      <th>bed</th>\n",
       "      <th>bench</th>\n",
       "      <th>chair</th>\n",
       "      <th>table</th>\n",
       "      <th>curr_winner</th>\n",
       "      <th>tc_pair</th>\n",
       "      <th>trialID</th>\n",
       "      <th>run</th>\n",
       "      <th>target_val</th>\n",
       "      <th>competitor_val</th>\n",
       "      <th>control_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0119174</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>39.00144</td>\n",
       "      <td>bench</td>\n",
       "      <td>chair</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.055895</td>\n",
       "      <td>0.916243</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>chair</td>\n",
       "      <td>bench/chair</td>\n",
       "      <td>0119174_neurosketch_320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.055895</td>\n",
       "      <td>0.916243</td>\n",
       "      <td>0.013931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0119174</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>39.00144</td>\n",
       "      <td>bench</td>\n",
       "      <td>chair</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934225</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>bed</td>\n",
       "      <td>bench/chair</td>\n",
       "      <td>0119174_neurosketch_320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.039085</td>\n",
       "      <td>0.467345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0119174</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>39.00144</td>\n",
       "      <td>bench</td>\n",
       "      <td>chair</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.970770</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>bench</td>\n",
       "      <td>bench/chair</td>\n",
       "      <td>0119174_neurosketch_320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970770</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.013258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0119174</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>39.00144</td>\n",
       "      <td>bench</td>\n",
       "      <td>chair</td>\n",
       "      <td>3</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.978927</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>bench</td>\n",
       "      <td>bench/chair</td>\n",
       "      <td>0119174_neurosketch_320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978927</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.008644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0119174</td>\n",
       "      <td>20</td>\n",
       "      <td>320</td>\n",
       "      <td>39.00144</td>\n",
       "      <td>bench</td>\n",
       "      <td>chair</td>\n",
       "      <td>4</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.967674</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>bench</td>\n",
       "      <td>bench/chair</td>\n",
       "      <td>0119174_neurosketch_320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967674</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.015431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      wID  viewpoint  trial  trialDuration target competitor  \\\n",
       "0      0  0119174         20    320       39.00144  bench      chair   \n",
       "1      0  0119174         20    320       39.00144  bench      chair   \n",
       "2      0  0119174         20    320       39.00144  bench      chair   \n",
       "3      0  0119174         20    320       39.00144  bench      chair   \n",
       "4      0  0119174         20    320       39.00144  bench      chair   \n",
       "\n",
       "   numSketch       bed     bench     chair     table curr_winner      tc_pair  \\\n",
       "0          0  0.026822  0.055895  0.916243  0.001040       chair  bench/chair   \n",
       "1          1  0.934225  0.026225  0.039085  0.000465         bed  bench/chair   \n",
       "2          2  0.006035  0.970770  0.002714  0.020481       bench  bench/chair   \n",
       "3          3  0.009842  0.978927  0.003784  0.007447       bench  bench/chair   \n",
       "4          4  0.019298  0.967674  0.001463  0.011564       bench  bench/chair   \n",
       "\n",
       "                   trialID  run  target_val  competitor_val  control_val  \n",
       "0  0119174_neurosketch_320  1.0    0.055895        0.916243     0.013931  \n",
       "1  0119174_neurosketch_320  1.0    0.026225        0.039085     0.467345  \n",
       "2  0119174_neurosketch_320  1.0    0.970770        0.002714     0.013258  \n",
       "3  0119174_neurosketch_320  1.0    0.978927        0.003784     0.008644  \n",
       "4  0119174_neurosketch_320  1.0    0.967674        0.001463     0.015431  "
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2000489150>]"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEECAYAAAAlEzNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZE0pyAQEUlzCgIRkTSnIBARSXP/P9WPn1x+dViFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ff3e34f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vgg_ts.groupby('numSketch')['target_val'].mean())\n",
    "plt.plot(vgg_ts.groupby('numSketch')['competitor_val'].mean(),color='green')\n",
    "plt.plot(vgg_ts.groupby('numSketch')['control_val'].mean(),color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plotting helper\n",
    "def get_vgg_timecourse(iv,DM):\n",
    "    trained_objs = np.unique(DM.target.values)\n",
    "    control_objs = [i for i in ['bed','bench','chair','table'] if i not in trained_objs]\n",
    "    t1 = trained_objs[0]\n",
    "    t2 = trained_objs[1]\n",
    "    c1 = control_objs[0]\n",
    "    c2 = control_objs[1]\n",
    "    target = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(t1)].mean().values,\n",
    "                   DM[DM.label==t2].groupby(iv)['{}_prob'.format(t2)].mean().values)).mean(0) ## target timecourse\n",
    "    foil = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(t2)].mean().values,\n",
    "                   DM[DM.label==t2].groupby(iv)['{}_prob'.format(t1)].mean().values)).mean(0) ## foil timecourse\n",
    "    control = np.vstack((DM[DM.label==t1].groupby(iv)['{}_prob'.format(c1)].mean().values,\n",
    "                        DM[DM.label==t1].groupby(iv)['{}_prob'.format(c2)].mean().values,\n",
    "                        DM[DM.label==t2].groupby(iv)['{}_prob'.format(c1)].mean().values,\n",
    "                        DM[DM.label==t2].groupby(iv)['{}_prob'.format(c2)].mean().values)).mean(0) ## control timecourse\n",
    "    \n",
    "    return target, foil, control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = []\n",
    "F = []\n",
    "C = []\n",
    "Sub = []\n",
    "for sub in subs:\n",
    "    inds =(vgg_ts['wID']==sub) \n",
    "    t,f,c = get_prob_timecourse(this_iv,vgg_ts[inds])\n",
    "    \n",
    "    \n",
    "    if len(T)==0:\n",
    "        T = t\n",
    "        F = f\n",
    "        C = c\n",
    "        DTF = t-f                \n",
    "        DTC = t-c\n",
    "        DFC = f-c\n",
    "    else:\n",
    "        T = np.hstack((T,t))\n",
    "        F = np.hstack((F,f))        \n",
    "        C = np.hstack((C,c)) \n",
    "        DTF = np.hstack((DTF,t-f))                \n",
    "        DTC = np.hstack((DTC,t-c))\n",
    "        DFC = np.hstack((DFC,f-c))\n",
    "    Sub.append([sub]*len(t))   \n",
    "\n",
    "## make longform version of dataframe to use in tsplot (difference btw conditions)                    \n",
    "Trial = np.tile(np.arange(len(t)),len(subs)*3)\n",
    "Condition = np.repeat(['trained-foil','trained-control','foil-control'],len(T))\n",
    "Sub = np.tile(np.array(flatten(Sub)),3)\n",
    "Prob = np.hstack((DTF,DTC,DFC))        \n",
    "assert len(Trial)==len(Condition)\n",
    "assert len(Sub)==len(Prob)\n",
    "assert len(Condition)==len(Sub)\n",
    "x = pd.DataFrame([Prob,Trial,Condition,Sub])\n",
    "x = x.transpose()\n",
    "x.columns = ['probability',lookup[this_iv],'condition','sub']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0110171', '0110172', '0111171', '0112171', '0112172', '0112173',\n",
       "       '0113171', '0115174', '0117171', '0118171', '0118172', '0119171',\n",
       "       '0119172', '0119173', '0119174', '0120171', '0120172', '0120173',\n",
       "       '0123171', '0123173', '0124171', '0125171', '0125172', '1121161',\n",
       "       '1130161', '1202161', '1203161', '1206161', '1206162', '1206163',\n",
       "       '1207162'], dtype=object)"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171_neurosketch', '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch', '1121161_neurosketch', '1130161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(['1121161_neurosketch', '1130161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch', '0110171_neurosketch', \n",
    "                '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', \n",
    "                '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', \n",
    "                '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
